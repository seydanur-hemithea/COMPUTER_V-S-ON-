{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1rDID7YUxRKIHi9lvl43wbBMBxtZ2FT4F",
      "authorship_tag": "ABX9TyPju6Ax/3OatHbdDCBBMRQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seydanur-hemithea/COMPUTER_V-S-ON-/blob/main/trans_haircolor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k-izawmdNI0Z"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import itertools\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchsummary import summary\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython.display import Image as ImageDisplay\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "From the address https://www.kaggle.com/jessicali9530/celeba-dataset:\n",
        "    - The folder named img_align_celebA\n",
        "    - And the file named list_attr_celeba.csv\n",
        "are downloaded and placed into the dataset directory of the project..\n",
        "'''\n",
        "\n",
        "image_dir = './dataset/celeba/images'\n",
        "attributes_file = './dataset/celeba/list_attr_celeba.csv'\n",
        "output_dir = './dataset/preprocessed_dataset_celeba'\n"
      ],
      "metadata": {
        "id": "6yQ8si_2PlkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The CSV file containing the feature vectors is read using pandas\n",
        "data = pd.read_csv(attributes_file)\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "dlJf5RnRPyRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We select 1,000 female celebrity images labeled with black or blonde hair as \"1\" and assign them to the related dataframes\n",
        "df_blackHair = data.loc[data['Black_Hair' ] == 1 & (data['Male'] == -1)].sample(n=1000)\n",
        "df_blond = data.loc[data['Blond_Hair'] == 1 & (data['Male'] == -1)].sample(n=1000)\n"
      ],
      "metadata": {
        "id": "dXj8IdSDQATf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's examine the first image with dark hair\n",
        "ImageDisplay(os.path.join(image_dir, df_blackHair.iloc[0]['image_id']))\n"
      ],
      "metadata": {
        "id": "4QBps_NLQDls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's examine the first image with blonde hair\n",
        "ImageDisplay(os.path.join(image_dir, df_blond.iloc[0]['image_id']))\n"
      ],
      "metadata": {
        "id": "YXOATtU8QSpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#To make it easier to access the names of the selected images during copying,\n",
        "#let's save them into separate lists\n",
        "\n",
        "domainA, domainB = [], []\n",
        "\n",
        "for index, row in df_blackHair.iterrows():\n",
        "    domainA.append(row['image_id'])\n",
        "\n",
        "for index, row in df_blond.iterrows():\n",
        "    domainB.append(row['image_id'])\n",
        "\n"
      ],
      "metadata": {
        "id": "yLB9M-xqQXZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Train and test data are generated by dividing the first 1000 selected images\n",
        "A_train, A_test = train_test_split(domainA, test_size=0.01, random_state=42)\n",
        "B_train, B_test = train_test_split(domainB, test_size=0.01, random_state=42)\n"
      ],
      "metadata": {
        "id": "K_XCsoPUQdQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the Train and Test datasets\n",
        "#Defining the paths for the train folders and creating the save directories\n",
        "A_train_dir = os.path.join(output_dir, 'train/A')\n",
        "B_train_dir = os.path.join(output_dir, 'train/B')\n",
        "\n",
        "os.makedirs(A_train_dir, exist_ok=True)\n",
        "os.makedirs(B_train_dir, exist_ok=True)\n",
        "\n",
        "## Copying data from the original location to the new destination\n",
        "for imageA, imageB in zip(A_train, B_train):\n",
        "    shutil.copy(os.path.join(image_dir, imageA), os.path.join(A_train_dir, imageA))\n",
        "    shutil.copy(os.path.join(image_dir, imageB), os.path.join(B_train_dir, imageB))\n",
        "#The paths of the train folders are defined and the save directories are created\n",
        "A_test_dir = os.path.join(output_dir, 'test/A')\n",
        "B_test_dir = os.path.join(output_dir, 'test/B')\n",
        "\n",
        "os.makedirs(A_test_dir, exist_ok=True)\n",
        "os.makedirs(B_test_dir, exist_ok=True)\n",
        "\n",
        "#We are copying from the original location to the new location\n",
        "for imageA, imageB in zip(A_test, B_test):\n",
        "    shutil.copy(os.path.join(image_dir, imageA), os.path.join(A_test_dir, imageA))\n",
        "    shutil.copy(os.path.join(image_dir, imageB), os.path.join(B_test_dir, imageB))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rO-wis3kQmGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def ___init__(self,root,transform=None,unaligned=False,mode='train'):\n",
        "    #use transform file\n",
        "    self.transform=transforms.Compose(transforms_)\n",
        "    self.unaligned=unaligned\n",
        "\n",
        "    self.files_A=sorted(glob.glob(os.path.join(root,'%s/A' % mode) + '/*.*'))\n",
        "    self.files_B=sorted(glob.glob(os.path.join(root,'%s/B' % mode) + '/*.*'))\n",
        "  def __getitem__(self,index):\n",
        "    #eğitim yapılırken her veri alışında bu fornksiyıona giriliyor ve veriler ön işlemden geçiyor\n",
        "\n",
        "    item_A=self.transform(Image.open(self.files_A[index%len(self.files_A)]))\n",
        "\n",
        "    if self.unaligned:\n",
        "      item_B=self.transform(Image.open(self.files_B[random.randint(0,len(self.files_B)-1)]))\n",
        "      else:\n",
        "        item_B=self.transform(Image.open(self.files_B[index%len(self.files_B)]))\n",
        "\n",
        "        return{'A':item_A,'B':item_B}\n",
        "    def __len__(self):\n",
        "      return max(len(self.files_A),len(self.files_B))"
      ],
      "metadata": {
        "id": "Z54rxVh9TYZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator blokları ve Generator yapay sinir ağı tasarımı\n"
      ],
      "metadata": {
        "id": "pw9t2VNvZh4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        conv_block = [  nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features)  ]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial convolution block\n",
        "        model = [   nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(input_nc, 64, 7),\n",
        "                    nn.InstanceNorm2d(64),\n",
        "                    nn.ReLU(inplace=True) ]\n",
        "\n",
        "        # Downsampling\n",
        "        in_features = 64\n",
        "        out_features = in_features*2\n",
        "        for _ in range(2):\n",
        "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                        nn.InstanceNorm2d(out_features),\n",
        "                        nn.ReLU(inplace=True) ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features*2\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(n_residual_blocks):\n",
        "            model += [ResidualBlock(in_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        out_features = in_features//2\n",
        "        for _ in range(2):\n",
        "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
        "                        nn.InstanceNorm2d(out_features),\n",
        "                        nn.ReLU(inplace=True) ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features//2\n",
        "\n",
        "        # Output layer\n",
        "        model += [  nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(64, output_nc, 7),\n",
        "                    nn.Tanh() ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-5AGsrnkY6fn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator Yapay Sinir ağı tasarımı"
      ],
      "metadata": {
        "id": "YCVAHXfXZ2Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # A bunch of convolutions one after another\n",
        "        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "                    nn.InstanceNorm2d(128),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "                    nn.InstanceNorm2d(256),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(256, 512, 4, padding=1),\n",
        "                    nn.InstanceNorm2d(512),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        # FCN classification layer\n",
        "        model += [nn.Conv2d(512, 1, 4, padding=1)]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x =  self.model(x)\n",
        "        # Average pooling and flatten\n",
        "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)\n"
      ],
      "metadata": {
        "id": "ra-TRsPhWrUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor2image(tensor):\n",
        "    #görselleştirme amacı ile gpu ya atılmış tensor verisi işlemci üzerinde imgeye dönüştürlür.\n",
        "    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n",
        "    if image.shape[0] == 1:\n",
        "        image = np.tile(image, (3,1,1))\n",
        "    return image.astype(np.uint8)\n",
        "\n",
        "class ReplayBuffer():\n",
        "    # Kayıp hesabı yapılırken Buffer a veri atıp çıkartıyoruz\n",
        "    def __init__(self, max_size=50):\n",
        "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0,1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size-1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return Variable(torch.cat(to_return))\n",
        "\n",
        "class LambdaLR():\n",
        "    # Learning rate decay ayarları burada yapılıyor\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    # Yapay sinir ağının ağırlıklarının uniform bir dağılımda ilklendirilmesi için bu fonksiyon kullanılıyor.\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "lRIQaeiMaORj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training parameters\n",
        "epoch=0\n",
        "n_epochs=50\n",
        "batchSize=1\n",
        "dataroot='./dataset/preprocessed_dataset_celeba/'\n",
        "lr=0.0002\n",
        "decay_epoch=3\n",
        "size=256\n",
        "input_nc=3\n",
        "output_nc = 3\n",
        "cuda =True\n",
        "n_cpu=8"
      ],
      "metadata": {
        "id": "5pIU7itTeMEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "if torch.cuda.is_available() and not cuda:\n",
        "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "###### Definition of variables ######\n",
        "# Networks\n",
        "netG_A2B = Generator(input_nc, output_nc)\n",
        "netG_B2A = Generator(output_nc, input_nc)\n",
        "netD_A = Discriminator(input_nc)\n",
        "netD_B = Discriminator(output_nc)\n",
        "\n",
        "if cuda:\n",
        "    netG_A2B.cuda()\n",
        "    netG_B2A.cuda()\n",
        "    netD_A.cuda()\n",
        "    netD_B.cuda()\n",
        "\n",
        "netG_A2B.apply(weights_init_normal)\n",
        "netG_B2A.apply(weights_init_normal)\n",
        "netD_A.apply(weights_init_normal)\n",
        "netD_B.apply(weights_init_normal)\n",
        "\n",
        "# Lossess\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "# Optimizers & LR schedulers\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
        "                                lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
        "\n",
        "# Inputs & targets memory allocation\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "input_A = Tensor(batchSize, input_nc, size, size)\n",
        "input_B = Tensor(batchSize, output_nc, size, size)\n",
        "target_real = Variable(Tensor(batchSize,1).fill_(1.0), requires_grad=False)\n",
        "target_fake = Variable(Tensor(batchSize,1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "# Dataset loader\n",
        "transforms_ = [ transforms.Resize(int(size*1.12), Image.BICUBIC),\n",
        "                transforms.RandomCrop(size),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
        "dataloader = DataLoader(ImageDataset(dataroot, transforms_=transforms_, unaligned=True),\n",
        "                        batch_size=batchSize, shuffle=True, num_workers=n_cpu)\n",
        "\n",
        "\n",
        "G_loss = []\n",
        "G_identity_loss = []\n",
        "G_gan_loss = []\n",
        "G_cycle_loss = []\n",
        "D_loss = []\n"
      ],
      "metadata": {
        "id": "mAG1Vw8YeRvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### Training ######\n",
        "pbar = tqdm(range(epoch, n_epochs))\n",
        "for epoch in pbar:\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        # Set model input\n",
        "        real_A = Variable(input_A.copy_(batch['A']))\n",
        "        real_B = Variable(input_B.copy_(batch['B']))\n",
        "\n",
        "        ###### Generators A2B and B2A ######\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Identity loss\n",
        "        # G_A2B(B) should equal B if real B is fed\n",
        "        same_B = netG_A2B(real_B)\n",
        "        loss_identity_B = criterion_identity(same_B, real_B)*5.0\n",
        "        # G_B2A(A) should equal A if real A is fed\n",
        "        same_A = netG_B2A(real_A)\n",
        "        loss_identity_A = criterion_identity(same_A, real_A)*5.0\n",
        "\n",
        "        # GAN loss\n",
        "        fake_B = netG_A2B(real_A)\n",
        "        pred_fake = netD_B(fake_B)\n",
        "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
        "\n",
        "        fake_A = netG_B2A(real_B)\n",
        "        pred_fake = netD_A(fake_A)\n",
        "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
        "\n",
        "        # Cycle loss\n",
        "        recovered_A = netG_B2A(fake_B)\n",
        "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
        "\n",
        "        recovered_B = netG_A2B(fake_A)\n",
        "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
        "\n",
        "        # Total loss\n",
        "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
        "        loss_G.backward()\n",
        "\n",
        "        optimizer_G.step()\n",
        "        ###################################\n",
        "\n",
        "        ###### Discriminator A ######\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        pred_real = netD_A(real_A)\n",
        "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
        "\n",
        "        # Fake loss\n",
        "        fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
        "        pred_fake = netD_A(fake_A.detach())\n",
        "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
        "\n",
        "        # Total loss\n",
        "        loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
        "        loss_D_A.backward()\n",
        "\n",
        "        optimizer_D_A.step()\n",
        "        ###################################\n",
        "\n",
        "        ###### Discriminator B ######\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        pred_real = netD_B(real_B)\n",
        "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
        "\n",
        "        # Fake loss\n",
        "        fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
        "        pred_fake = netD_B(fake_B.detach())\n",
        "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
        "\n",
        "        # Total loss\n",
        "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
        "        loss_D_B.backward()\n",
        "\n",
        "        optimizer_D_B.step()\n",
        "        ###################################\n",
        "\n",
        "        pbar.set_postfix({'loss_G': loss_G.item(),\n",
        "                    'loss_G_cycle': (loss_cycle_ABA .item()+ loss_cycle_BAB.item()), 'loss_D': (loss_D_A.item()+ loss_D_B.item())})\n",
        "        G_loss.append(loss_G.item())\n",
        "        G_identity_loss.append(loss_identity_A.item() + loss_identity_B.item())\n",
        "        G_gan_loss.append(loss_GAN_A2B.item() + loss_GAN_B2A.item())\n",
        "        G_cycle_loss.append(loss_cycle_ABA .item()+ loss_cycle_BAB.item())\n",
        "        D_loss.append(loss_D_A.item()+ loss_D_B.item())\n",
        "    # Update learning rates\n",
        "    lr_scheduler_G.step()\n",
        "    lr_scheduler_D_A.step()\n",
        "    lr_scheduler_D_B.step()\n",
        "\n",
        "    # Save models checkpoints\n",
        "    torch.save(netG_A2B.state_dict(), 'output/netG_A2B.pth')\n",
        "    torch.save(netG_B2A.state_dict(), 'output/netG_B2A.pth')\n",
        "    torch.save(netD_A.state_dict(), 'output/netD_A.pth')\n",
        "    torch.save(netD_B.state_dict(), 'output/netD_B.pth')"
      ],
      "metadata": {
        "id": "cDwx3g4renBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Losses During Training\")\n",
        "plt.plot(G_loss,label=\"G\")\n",
        "plt.plot(G_identity_loss,label=\"G_identity\")\n",
        "plt.plot(G_gan_loss, label=\"G_GAN\")\n",
        "plt.plot(G_cycle_loss, label=\"G_cycle\")\n",
        "plt.plot(D_loss, label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zaz1a4wLetxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Losses During Training\")\n",
        "plt.plot(G_loss,label=\"G\")\n",
        "plt.plot(D_loss, label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CdvfaDr6eujT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Losses During Training\")\n",
        "plt.plot(G_identity_loss,label=\"G_identity\")\n",
        "plt.plot(D_loss, label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1LKLjTGoeyOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Losses During Training\")\n",
        "plt.plot(G_cycle_loss, label=\"G_cycle\")\n",
        "plt.plot(D_loss, label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "79TdtVU0e27v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Losses During Training\")\n",
        "plt.plot(G_gan_loss, label=\"G_GAN\")\n",
        "plt.plot(D_loss, label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1YHVdJA0e5Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Networks\n",
        "netG_A2B = Generator(input_nc, output_nc)\n",
        "netG_B2A = Generator(output_nc, input_nc)\n",
        "\n",
        "if cuda:\n",
        "    netG_A2B.cuda()\n",
        "    netG_B2A.cuda()\n",
        "# Load state dicts\n",
        "netG_A2B.load_state_dict(torch.load('./output/netG_A2B.pth'))\n",
        "netG_B2A.load_state_dict(torch.load('./output/netG_B2A.pth'))\n",
        "Yürütme çıkışı\n",
        "0KB\n",
        "\ttext/plain\n",
        "\t\t<All keys matched successfully>\n",
        "\n",
        "Kod hücresi <undefined>\n",
        "# %% [code]\n",
        "# Inputs & targets memory allocation\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "input_A = Tensor(batchSize, input_nc, 313, 313)\n",
        "input_B = Tensor(batchSize, output_nc, 313, 313)\n",
        "\n",
        "transforms_ = [transforms.Resize((313,313), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
        "dataloader = DataLoader(ImageDataset(dataroot, transforms_=transforms_, mode='test'),\n",
        "                        batch_size=batchSize, shuffle=False, num_workers=n_cpu)\n",
        "###################################\n",
        "\n",
        "\n",
        "save_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(size=(218,178)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "###### Testing######\n",
        "\n",
        "# Create output dirs if they don't exist\n",
        "if not os.path.exists('output/A'):\n",
        "    os.makedirs('output/A')\n",
        "if not os.path.exists('output/B'):\n",
        "    os.makedirs('output/B')\n",
        "\n",
        "for i, batch in enumerate(dataloader):\n",
        "    print(batch['A'].shape)\n",
        "    # Set model input\n",
        "    real_A = Variable(input_A.copy_(batch['A']))\n",
        "    real_B = Variable(input_B.copy_(batch['B']))\n",
        "\n",
        "    # Generate output\n",
        "    fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
        "    fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\n",
        "\n",
        "    # Save image files\n",
        "    fake_A = fake_A.detach().cpu()\n",
        "    fake_A = [save_transforms(x_) for x_ in fake_A]\n",
        "    fake_B = fake_B.detach().cpu()\n",
        "    fake_B = [save_transforms(x_) for x_ in fake_B]\n",
        "    save_image(fake_A, 'output/A/%04d.png' % (i+1))\n",
        "    save_image(fake_B, 'output/B/%04d.png' % (i+1))\n",
        "\n",
        "    sys.stdout.write('\\rGenerated images %04d of %04d' % (i+1, len(dataloader)))\n",
        "\n",
        "sys.stdout.write('\\n')"
      ],
      "metadata": {
        "id": "onRHNMoTfAl7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}